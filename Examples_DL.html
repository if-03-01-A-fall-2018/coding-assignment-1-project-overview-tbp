<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <link href='MainpageCss.css' rel='stylesheet'>
    <meta charset="utf-8">
    <title>A.I M.L & D.L</title>
  </head>
  <body>
    <header>
      <div class="wrapper">
        <nav>
          <ul>
            <li><a href="MainPage.html">HOME</a></li>
            <li><a>Artificial Inteligence</a>
              <ul>
                <li><a href="About_AI.html">About</a></li>
                <li><a href="History_AI.html">History</a></li>
                <li><a href="Examples_AI.html">Examples</a></li>
              </ul>
            </li>
            <li><a>Machine Learning</a>
              <ul>
                <li><a href="About_ML.html">About</a></li>
                <li><a href="History_ML.html">History</a></li>
                <li><a href="Examples_ML.html">Examples</a></li>
              </ul>
            </li>
            <li><a>Deep Learning</a>
              <ul>
                <li><a href="About_DL.html">About</a></li>
                <li><a href="History_DL.html">History</a></li>
                <li><a href="Examples_DL.html">Examples</a></li>
              </ul>
            </li>
          </ul>
        </nav>
      </div>
    </header>
    <h1>Deep Learning</h1>
    <hr>
    <h2>Automatic speech recognition</h2>
    <p>Large-Scale automatic speech recognizing is the first and most convincing successful case of deep learning. LSTM RNNs can learn "Very Deep Learning" tasks[2] that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates is competitive with traditional speech recognizers on certain tasks.</p>
    <p>The initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major dialects of American English, where each speaker reads 10 sentences. Its small size lets many configurations be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak phone bigram language models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991. </p>
    <p></p>

  </body>
</html>
